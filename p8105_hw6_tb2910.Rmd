---
title: "Homework 6"
author: "Teshawna Badu"
date: 12/04/2021
output: github_document
---

I'm an R Markdown document!

```{r setup}
library(tidyverse)
library(readr)
library(modelr)
library(patchwork)
```


## Question 1 
```{r, message=FALSE}
birthweight_df = 
  read_csv("./birthweight.csv") %>% 
  mutate(babysex = factor(babysex),
         frace = factor(frace),
         malform = factor(malform),
         mrace = factor(mrace)) %>% 
  mutate(bwt = bwt*0.00220462)
  birthweight_df %>% 
  skimr::skim()
```
From the summary statistics provided by skimr, we see that there are no missing data.

To predict the best model to use in this scenario, we can first start by computing the pearson correlation coefficient between each variable and birth weight.
```{r warning=FALSE}
birthweight_df %>%
  map(~cor(as.numeric(.x), pull(birthweight_df, bwt), method = "pearson")) %>%
  as_tibble() %>%
  pivot_longer(babysex:wtgain,
               names_to = "variables",
               values_to = "r") %>%
  knitr::kable()
```
From this analysis, we can see that `bhead` (baby's head circumference) and `blength` (baby's length at birth) are the only variables that have pearson correlation coefficient greater than 0.5. I will choose to fit a linear regression model with these two variables to predict birth weight. 

```{r}
proposed_model <- lm(bwt ~ bhead + blength, data = birthweight_df)
```

We can now plot model residual as a function of model prediction.
```{r}
# Get model predictions
# Get model residuals
# Plot line graph of model residual as a function of model prediction
birthweight_df %>%
  add_predictions(proposed_model) %>%
  add_residuals(proposed_model) %>%
  ggplot(aes(x = pred, y = resid)) +
  geom_line() +
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5)) +
  labs(
    title = "Model Residual as a function of Model Prediction",
    x = "Prediction",
    y = "Residual"
  )
```
After plotting the model residual as a function of model prediction, we see the model mostly underestimates birth weight for predicted values less than around 4.4 pounds. For predicted birth weights greater than 4.4 pounds, the residual tends to oscillate, splitting over and under zero.

We can now get the cross-validated predicted error for our proposed model. Additionally, we can look at two other linear regression models: first with birth length and gestational age without interaction term and the second with head circumference at birth, birth length, sex, and all interaction terms.

First we can create 100 80-20 training-test splits, then run of the three models on each of the 100 training data sets. Lastly, we will test each of the three models on each of the 100 training data and also calculate RMSE.
```{r}
crossvalidate_df <- crossv_mc(birthweight_df, 100) %>%
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble)
  ) %>%
  mutate(
    proposed_model = map(train, ~lm(bwt ~ bhead + blength, data = .x)),
    fit_one = map(train, ~lm(bwt ~ blength + gaweeks, data = .x)),
    fit_two = map(train, ~lm(bwt ~ bhead*blength*babysex, data = .x))
  ) %>%
  mutate(
    rmse_proposed_model = map2_dbl(proposed_model, test, ~rmse(model = .x, data = .y)),
    rmse_fit_one = map2_dbl(fit_one, test, ~rmse(model = .x, data = .y)),
    rmse_fit_two = map2_dbl(fit_two, test, ~rmse(model = .x, data = .y))
  )
```


We can now compare the root mean squared error of the three models with a boxplot.
We will create a boxplot to visualize the distribution of RMSE for the 100 testing

```{r}
crossvalidate_df %>%
  select(starts_with("rmse")) %>%
  pivot_longer(everything(),
               names_to = "model",
               values_to = "rmse",
               names_prefix = "rmse_") %>%
  mutate(model = fct_inorder(model)) %>%
  ggplot(aes(x = model, y = rmse)) +
  geom_boxplot() +
  theme_bw() +
  labs(
    x = "Model",
    y = "RMSE",
    title = "RMSE Distribution by Model"
  ) +
  theme(plot.title = element_text(hjust = 0.5))
```
We see that our proposed model and the suggested model with predictors head circumference, birth length, sex, and all interaction terms have similar root mean squared error. However, the suggested model with predictors birth length and gestational age without interaction term has the highest root mean squared error among the three models.


## Question 2
```{r}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())
```


##### Use 5000 bootstrap samples and for sample produce estimates of r hat sqaure and log($\hat\beta_0$ * $\hat\beta_1$)

```{r}
weather_bootstrap = 
  weather_df %>% 
  select(tmax, tmin) %>% 
  bootstrap(n = 5000, id = "strap_number") %>%
  mutate(
    models = map(.x = strap, ~lm(tmax ~ tmin, data = .x)),
    results_coeff = map(models, broom::tidy),
    results_rsquare = map(models, broom::glance)
  ) %>% 
  select(strap_number, results_coeff, results_rsquare) %>% 
  unnest(results_coeff) %>% 
  select(strap_number,term, estimate, results_rsquare) %>% 
  unnest(results_rsquare) %>% 
  select(strap_number, term, estimate, r.squared)
```

```{r}
beta0_df = 
  weather_bootstrap %>% 
  filter(term == "(Intercept)") %>% 
  select(strap_number, estimate) %>% 
  rename(beta0 = estimate)
beta1_df = 
  weather_bootstrap %>% 
  filter(term == "tmin") %>%
  select(strap_number,estimate) %>% 
  rename(beta1 = estimate)
betas_df = 
  inner_join(beta0_df, beta1_df, by = "strap_number") %>% 
  mutate(log_beta = log(beta0*beta1))
betas_df %>% 
  ggplot(aes(log_beta)) +
  geom_density()
```

Overall we see that The distribution of log($\hat\beta_0$ * $\hat\beta_1$) looks fairly normally distributed.


##### We can now identify the 2.5% and 97.5% quantiles to provide a 95% confidence interval for log($\hat\beta_0$ * $\hat\beta_1$)
```{r}
quantile(betas_df$log_beta, c(.025, 0.975)) 
```
Our results show that the 95% confidence interval for log($\hat\beta_0$ * $\hat\beta_1$) is (1.96, 2.05).

##### We will repeat the same proccess for r hat sqaure
```{r}
rsquare_df = 
  weather_bootstrap %>% 
  select(strap_number, r.squared) %>% 
  distinct(strap_number, .keep_all = TRUE)
rsquare_df %>% 
  ggplot(aes(r.squared)) +
  geom_density()
```
The distribution of r hat square looks fairly normal but with a slightly left-skewness. 

```{r}
quantile(rsquare_df$r.squared, c(.025, 0.975)) 
```
Our results show that the 95% confidence interval for r hat square is (0.89, 0.92).

